% Background Information
\section{Background Information}
\subsection{Co-evolution of morphology and control}
Talk about current research of co-evolution of morphology and control
Embodied cognition and how to tackle this problem
Premature convergence and how to tackle this problem
What are issues and solutions on co-evolution.

\subsection{Robustness and generalizability}
Robustness refers to the ability of an agent to maintain desirable behavior despite variations or perturbations in its input and output data \cite{Ravi_Mangal_2019, Charles_Packer_2019, Xu_Mengdi_2022}. Consequently, a robust agent is less susceptible to input and output perturbations. This makes robustness a critical attribute, as inputs and outputs from the training environment can differ significantly from those in the testing environment, especially in real-world scenarios. For instance, an input perturbation can be caused by a sensor defect, resulting in slight measurement errors. In reinforcement learning, this means that we need to build robustness against the uncertainty of state observations and the actual state. Similarly, an output perturbation can result from a motory issue of the agent. In reinforcement learning, this means that we need to build robustness against uncertain actions between the actions generated by the agent and the conducted actions \cite{Xu_Mengdi_2022}. 

On the other hand, generalizability refers to the ability of an agent to maintain desirable behavior under different conditions to those encountered during training. It assumes correct input and output data and is concerned on the actual differences between the training environment and the testing or production environment. Testing generalization is divided into two distinctive parts. The first part is called interpolation, which requires the agent to perform well in environments similar to those of training, with both the testing and training environment parameters drawn from the same distribution. The second part is called extrapolation, which requires the agent to perform well in environments different from those of training, with the testing and training environment parameters drawn from separate distributions \cite{Charles_Packer_2019, Xu_Mengdi_2022}.

There are some ways to achieve more robust agents. In this example \cite{Ines_Valentin_2022}, they compared the robustness of the models DENSER and NSGA-Net on the CIFAR-10 image classification task. It was found that the DENSER model exhibited an higher robustness, which concludes that certain architectures inherently have a higher degree of exhibiting robustness. Furthermore, one of the most popular method is adverserial training, where the agent is trained on adverserially perturbated training data. One way of doing this is finding the worst case perturbation at each training episode and training the model using the dataset with this perturbation \cite{Kai_Liang_Tan_2020}. The two main approaches to achieving generalizable agents are either training a generalist agent, which involves a trade-off in performance under specific conditions compared to a specialist agent, as shown by Triebold et al. \cite{Corinna_Triebold}, or developing agents that can explicitly adapt to certain conditions \cite{Charles_Packer_2019}. In this paper, we will focus on the first approach. Recently, there has been a growing recognition of the importance of using variability to train better and more generalized agents. Raviv et al. \cite{Limor_Raviv_2022} discusses the relationship between variability and learning outcomes, highlighting a universal principle that variability enhances learning. This principle also holds true for machine learning, where employing a more variable learning curriculum can improve an agent's generalizability across a wide range of morphologies. Similarly, Stensby et al. \cite{Emma_Stensby_2021}, applied the same principle of variability by training agents in a curriculum of environments generated by the Paired Open-Ended Trailblazer (POET) algorithm, where the generated environments were incrementally more difficult, enabling the agent to learn more efficient and complex behaviors. These studies demonstrate that using a variable learning curriculum increases both robustness and generalizability.
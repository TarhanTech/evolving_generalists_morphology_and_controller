
\section{Method}
    In this section, we describe the algorithm used to promote generalizability and the conducted experiments. All the code used for these experiments are publicly accessible\footnote{The code used for our experiments: \url{https://github.com/TarhanTech/evolving_generalists_morphology_and_controller}}.
    
    \subsection{Algorithm}
        
        For the evolution of our MC-pair, we adopted the same algorithm initially proposed by Triebold et al. \cite{Corinna_Triebold} with some minor modifications. They explored different training schedules, which determined the order in which the training set was used during the evolutionary process. They found that using an incremental training schedule, where the environment is modified incrementally after every generation, yields the best results. Therefore, we will only consider the incremental training schedule in our analysis.
        
        Consider the set of training environments $T = \{t_1, t_2, \ldots, t_n\}$, which was established prior to training, and an empty generalist MC-pair set $G = \{\}$, which will store the evolved generalist MC-pairs throughout the evolutionary process, and an empty environment partition set $E = \{\}$, which will store partitions of the set $T$ that correspond to the a generalist MC-pair in $G$. The algorithm will partition the environments and train a generalist MC-pair for each partition. This is necessary when the environments differ significantly from one another and a single generalist MC-pair is not feasible. 

            \begin{algorithm}[H]
            \footnotesize % Reduce font size for the algorithm
            \caption{Creating Generalist MC-pairs}
            \begin{algorithmic}[1] % The [1] ensures lines are numbered
                \State $T \gets \{t_1, t_2, \ldots, t_n\}$
                \State $G \gets \{\}$ 
                \State $E \gets \{\}$
                \While{$T$ is non-empty}
                    \State $\overrightarrow{MC}_{\text{best}} \gets \{\}$
                    \State $g_{\text{best}} \gets -\infty$
                    \State Initialize search algorithm
                    \State
                    \While{$g_{\text{best}}$ improved within $h$ gen. or $maxGen$ not reached}
                        \State $t_i \gets$ next training env.
                        \State $pop \gets$ gen. pop. of MC-pairs \& eval. to $t_i$
                        \State $\overrightarrow{MC}_{\text{pop,best}} \gets \{w_1, w_2, \ldots, w_n, m_1, m_2 \ldots, m_m\}$
                        \State $g_{\text{pop,best}} \gets$ eval. generalist score for $\overrightarrow{MC}_{\text{pop,best}}$
                        \If{$g_{\text{pop,best}} > g_{\text{best}}$}
                            \State $\overrightarrow{MC}_{\text{best}} \gets \overrightarrow{MC}_{\text{pop,best}}$
                            \State $g_{\text{best}} \gets g_{\text{pop,best}}$
                        \EndIf
                        \State Update search params.
                    \EndWhile
                    \State
                    \State $f_{\text{scores}} \gets \{\text{eval. } \overrightarrow{MC}_{\text{best}} \text{ on all } T\}$
                    \State $f_{\mu} \gets$ mean fitness on all env.
                    \State $f_{\sigma} \gets$ std dev of fitness scores
                    \State $P \gets \{\}$
                    \For{\textbf{each} $fitness$ in $f_{\text{scores}}$}
                        \If{$fitness \geq (f_{\mu} - f_{\sigma})$}
                            \State add $t$ of $T$ corresponding to $fitness$ to $P$ and remove from $T$
                        \EndIf
                    \EndFor
                    \State append $\overrightarrow{MC}_{\text{best}}$ to $G$
                    \State append $P$ to $E$
                    \State (async) Finish training on the partition
                \EndWhile
                \State \Return $G,E$
            \end{algorithmic}
            \end{algorithm}

        The evolutionary process starts by initializing the first generation of MC-pairs, comprising both the ANN weights $\overrightarrow{W} = \{w_1, w_2, \ldots, w_n\}$ and the morphology parameters $\overrightarrow{M} = \{m_1, m_2, \ldots, m_n\}$. For the optimization process, $\overrightarrow{W}$ and $\overrightarrow{M}$ are concatenated into a singular vector \newline $\overrightarrow{MC} = \{w_1, w_2, \ldots, w_n, m_1, m_2 \ldots, m_m\}$ and fed to the XNES optimizer. Because the order of magnitude of the ANN and morphology parameters are very different, we encode the morphology parameters to the same order of magnitude as the ANN parameters.

        After every generation $i$, each MC-pair of the population is evaluated on the current training environment $t_i$, and the MC-pair with the highest fitness score, denoted as $\overrightarrow{MC}_{\text{pop,best}}$, undergoes further evaluation on the entire training set $T$, producing a generalist score $g_{\text{pop,best}}$. If this generalist score is an improvement over $g_{\text{best}}$, then $g_{\text{pop,best}}$ replaces $g_{\text{best}}$, and $\overrightarrow{MC}_{\text{pop,best}}$ replaces $MC_{\text{best}}$. After $h$ number of generation, if no improvement is found or $maxGen$ is reached, the evolutionary process is stagnated and the current $MC_{\text{best}}$ is evaluated on the training set $T$, returning a list of fitness scores $f_{\text{scores}}$ for each environment along with the corresponding mean $f_{\mu}$ and standard deviation $f_{\sigma}$. For each environment in $T$, where its fitness in $f_{\text{scores}}$ scored higher than $f_{\mu} - f_{\sigma}$ will be added to partition $P$ and removed from $T$. Subsequently, $\overrightarrow{MC}_{\text{best}}$ is appended to $G$ and $P$ to $E$. Finally, we can similarly continue training asynchronously only on this specific partition to further increase its fitness. This process repeats until $T$ is empty, and thus every environment belongs to a partition, which then corresponds to a generalist MC-pair. 

        We integrated a penalty function within the fitness evaluation to ensure adherence to the constraints set for the morphological parameters. This function considers the decoded morphological parameters $\overrightarrow{M}$, alongside the lower and upper bounds of the constraints, $C_\text{lb}$ and $C_\text{ub}$ respectively, a scalar $\alpha$, and a growth rate $r^i$, where $i$ is the number of generations. The penalty function is defined as:
        {\footnotesize
            \begin{equation}
                Penalty = \alpha r^i \cdot \sum(
                    \max(0, C_\text{lb} - \overrightarrow{M}) + 
                    \max(0, \overrightarrow{M} - C_\text{ub})
                )
            \end{equation}
        }
        Thus the generalist fitness function then becomes:
        {\footnotesize
            \begin{equation}
                g_{\text{best}} = \frac{1}{|T|} \sum_{i=1}^{|T|}(
                    evaluate(\overrightarrow{MC}, t_i) - Penalty
                ) 
            \end{equation}
        }
        Here $evaluate(\overrightarrow{MC}, t_i)$ represents the evaluation function, returning the score for the MC-pair of that generation on the training environment $t_i$ with the corresponding reward functions for Ant-v4 \cite{Gymnasium2023}.

    \subsection{Experiments}
        A total of three different experiments where done for this paper. These different experiments will provide a valuable basis for comparison with the partitioned approach explained previously.
        \subsubsection{Experiment 1: One generalist}
            The first experiment is similar to the algorithm described previously, but where the partitioning is disabled. This will result in only one generalist MC-pair that should handle all the environments. The reason for this is because the of the unpredictability of discovering a generalist MC-pair, due to it not being the objective function, but a secondary outcome of the method used.
        \subsubsection{Experiment 2: Partitioned generalist}
            The second experiment is the same as the algorithm described previously. In here, we will try to find a set of generalist MC-pairs where each can handle a partition of all the environments. 
        \subsubsection{Experiment 3: Specialist for each environment}
            The third experiment is executed to observe how much the other two experiments are losing on possible fitness for each environment. For this, we will evolve a specialist MC-pair for each environment.